"""
AST Transformer for Partial Parameter Streaming

Analyzes function code to:
1. Identify return value construction (dict with field assignments)
2. Track which variables contribute to which fields
3. Find computation points for each field
4. Generate transformed code that:
   - Publishes fields as they're computed
   - Invokes next function after first field is ready
   - Receiver resolves futures on-demand
"""

import ast
import re
from dataclasses import dataclass, field
from typing import List, Dict, Set, Tuple, Optional, Any


@dataclass
class FieldComputation:
    """Represents when and how a return field is computed"""
    field_name: str           # Name of the field in the return dict
    source_variable: str      # Variable name that holds the value
    computed_at_line: int     # Line number where the value is computed
    assignment_node: Any      # AST node of the assignment (for insertion point)
    is_synthetic: bool = False  # True when source_variable was generated by the analyzer
    value_node: Any = None      # Original AST value node (for extracting source text)


@dataclass
class StreamingAnalysis:
    """Result of analyzing a function for streaming potential"""
    can_stream: bool          # Whether streaming is possible
    reason: str               # Explanation of decision
    handler_name: str         # Name of the handler function
    return_line: int          # Line number of return statement
    return_node: Any          # AST node of return statement
    fields: List[FieldComputation]  # Ordered list of field computations


class StreamingAnalyzer:
    """
    Analyze a Python source file to determine streaming opportunities.
    
    Looks for patterns like:
        def lambda_handler(event, context):
            field1 = compute_field1()
            field2 = compute_field2()
            field3 = compute_field3()
            
            result = {
                "field1": field1,
                "field2": field2,
                "field3": field3
            }
            return result
    """
    
    def __init__(self):
        self.assignments: Dict[str, Tuple[int, ast.AST]] = {}  # var_name -> (line, node)
        self.return_node = None
        self.return_line = 0
        self.return_var = None  # Variable name if return is `return var`
        self.return_dict = None  # Dict contents if return is `return {...}`
        self.handler_node = None
        self.handler_name = ""
    
    def analyze(self, source: str) -> StreamingAnalysis:
        """
        Analyze source code for streaming opportunities.
        
        Args:
            source: Python source code as string
            
        Returns:
            StreamingAnalysis with results
        """
        try:
            tree = ast.parse(source)
        except SyntaxError as e:
            return StreamingAnalysis(
                can_stream=False,
                reason=f"Syntax error: {e}",
                handler_name="",
                return_line=0,
                return_node=None,
                fields=[]
            )
        
        # Find the handler function
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                if node.name in ('lambda_handler', 'handler', 'main'):
                    self.handler_node = node
                    self.handler_name = node.name
                    break
        
        if not self.handler_node:
            return StreamingAnalysis(
                can_stream=False,
                reason="No handler function found (lambda_handler, handler, or main)",
                handler_name="",
                return_line=0,
                return_node=None,
                fields=[]
            )
        
        # Collect all assignments in the handler
        self._collect_assignments(self.handler_node)
        
        # Find the return statement
        self._find_return(self.handler_node)
        
        if not self.return_node:
            return StreamingAnalysis(
                can_stream=False,
                reason="No return statement found",
                handler_name=self.handler_name,
                return_line=0,
                return_node=None,
                fields=[]
            )
        
        # Analyze what's being returned
        fields = self._analyze_return()
        
        if len(fields) < 2:
            return StreamingAnalysis(
                can_stream=False,
                reason=f"Need at least 2 streamable fields, found {len(fields)}",
                handler_name=self.handler_name,
                return_line=self.return_line,
                return_node=self.return_node,
                fields=fields
            )
        
        # Check that fields are computed at different lines
        unique_lines = set(f.computed_at_line for f in fields)
        if len(unique_lines) < 2:
            return StreamingAnalysis(
                can_stream=False,
                reason="All fields computed at same line, no streaming benefit",
                handler_name=self.handler_name,
                return_line=self.return_line,
                return_node=self.return_node,
                fields=fields
            )
        
        return StreamingAnalysis(
            can_stream=True,
            reason="OK",
            handler_name=self.handler_name,
            return_line=self.return_line,
            return_node=self.return_node,
            fields=sorted(fields, key=lambda f: f.computed_at_line)
        )
    
    def _collect_assignments(self, func_node: ast.FunctionDef):
        """Collect all variable assignments in the function"""
        for node in ast.walk(func_node):
            if isinstance(node, ast.Assign):
                for target in node.targets:
                    if isinstance(target, ast.Name):
                        self.assignments[target.id] = (node.lineno, node)
            elif isinstance(node, ast.AnnAssign) and isinstance(node.target, ast.Name):
                self.assignments[node.target.id] = (node.lineno, node)
    
    def _find_return(self, func_node: ast.FunctionDef):
        """Find the return statement in the function"""
        for node in ast.walk(func_node):
            if isinstance(node, ast.Return) and node.value:
                self.return_node = node
                self.return_line = node.lineno
                
                # Check if returning a variable or inline dict
                if isinstance(node.value, ast.Name):
                    self.return_var = node.value.id
                    # Look up the variable's assignment
                    if self.return_var in self.assignments:
                        assign_line, assign_node = self.assignments[self.return_var]
                        # Check if assigned to a dict
                        if isinstance(assign_node, ast.Assign):
                            if isinstance(assign_node.value, ast.Dict):
                                self.return_dict = assign_node.value
                elif isinstance(node.value, ast.Dict):
                    self.return_dict = node.value
                
                break  # Use first return statement
    
    def _analyze_return(self) -> List[FieldComputation]:
        """Analyze the return dict to find field computations.

        Handles multiple patterns:
          1. ast.Name        – return {'f': my_var}
          2. ast.Dict         – return {'f': {'a': x, 'b': y}}
             including **-unpacking: return {'f': {**base, 'extra': v}}
          3. ast.Call         – return {'f': compute(...)}
          4. ast.BinOp / other – best-effort Name scan
        """
        fields = []

        if not self.return_dict:
            return fields

        for key_node, value_node in zip(self.return_dict.keys, self.return_dict.values):
            # Get field name
            if isinstance(key_node, ast.Constant):
                field_name = str(key_node.value)
            elif isinstance(key_node, ast.Str):  # Python 3.7 compat
                field_name = key_node.s
            else:
                continue

            result = self._resolve_value(field_name, value_node)
            if result:
                fields.append(result)

        return fields

    # ------------------------------------------------------------------
    # Helpers for _analyze_return
    # ------------------------------------------------------------------

    def _resolve_value(self, field_name: str, value_node: ast.AST) -> Optional[FieldComputation]:
        """Resolve a single return-dict value to a FieldComputation.

        Strategy per node type:
        * ast.Name  – direct variable lookup (original behaviour)
        * ast.Dict  – collect all ast.Name leaves, pick the latest
                      assignment as the computation point.  If the dict
                      uses ** unpacking (keys contain None), the spread
                      variable is included.
        * ast.Call  – look for the most-recent assignment whose RHS is
                      this call (pattern: ``x = func(); return {'f': func()}``)
                      or fall back to scanning Name nodes in arguments.
        * fallback  – walk the AST subtree for any ast.Name references.
        """

        # ── Pattern 1: simple variable reference ────────────────────
        if isinstance(value_node, ast.Name):
            return self._field_from_name(field_name, value_node.id)

        # ── Pattern 2: inline / spread dict ─────────────────────────
        if isinstance(value_node, ast.Dict):
            return self._field_from_dict(field_name, value_node)

        # ── Pattern 3: function call ────────────────────────────────
        if isinstance(value_node, ast.Call):
            return self._field_from_call(field_name, value_node)

        # ── Fallback: walk for any Name references ──────────────────
        return self._field_from_names_in_subtree(field_name, value_node)

    def _field_from_name(self, field_name: str, var_name: str) -> Optional[FieldComputation]:
        """Resolve a bare variable name."""
        if var_name in self.assignments:
            line, node = self.assignments[var_name]
            # Use end_lineno so that for multi-line assignments like
            #   kmers = {
            #       'key': value,
            #   }
            # we insert AFTER the closing brace, not after the opening line.
            end_line = getattr(node, 'end_lineno', line)
            return FieldComputation(
                field_name=field_name,
                source_variable=var_name,
                computed_at_line=end_line,
                assignment_node=node,
            )
        return None

    def _field_from_dict(self, field_name: str, dict_node: ast.Dict) -> Optional[FieldComputation]:
        """Resolve an inline dict (possibly with ** unpacking).

        Collects every ast.Name in keys and values, looks up assignments,
        and uses the latest (highest line-number) assignment as the point
        where the field is fully ready.

        For the source_variable we need something the publisher can
        reference.  We synthesise a variable name ``_stream_<field>``
        and record that we need an extra assignment injected by the
        transformer (stored in ``self._synthetic_vars``).
        """
        names = self._collect_names(dict_node)
        return self._latest_assignment_field(field_name, names, dict_node)

    def _field_from_call(self, field_name: str, call_node: ast.Call) -> Optional[FieldComputation]:
        """Resolve an inline function call.

        If the same call appears as the RHS of a known assignment, use
        that variable.  Otherwise scan function arguments for Name refs.
        """
        # Check if the call's func is a Name we can match against
        # assignments (e.g.  result = compute(); return {'f': compute()})
        if isinstance(call_node.func, ast.Name):
            func_name = call_node.func.id
            # Look for an assignment whose RHS calls this function
            for var_name, (line, node) in self.assignments.items():
                if isinstance(node, ast.Assign) and isinstance(node.value, ast.Call):
                    if isinstance(node.value.func, ast.Name) and node.value.func.id == func_name:
                        end_line = getattr(node, 'end_lineno', line)
                        return FieldComputation(
                            field_name=field_name,
                            source_variable=var_name,
                            computed_at_line=end_line,
                            assignment_node=node,
                        )

        # Fallback: scan arguments for variable references
        names = self._collect_names(call_node)
        return self._latest_assignment_field(field_name, names, call_node)

    def _field_from_names_in_subtree(self, field_name: str, node: ast.AST) -> Optional[FieldComputation]:
        """Generic fallback: walk the subtree for Name references."""
        names = self._collect_names(node)
        return self._latest_assignment_field(field_name, names, node)

    # ------------------------------------------------------------------
    # Shared utilities
    # ------------------------------------------------------------------

    def _collect_names(self, node: ast.AST) -> List[str]:
        """Collect all ast.Name ids referenced anywhere inside *node*."""
        return [n.id for n in ast.walk(node) if isinstance(n, ast.Name)]

    def _latest_assignment_field(
        self, field_name: str, names: List[str], origin_node: ast.AST
    ) -> Optional[FieldComputation]:
        """Given a list of variable names, find the one assigned at the
        latest (highest) line number and build a FieldComputation.

        If the value is an inline expression (not a single variable), we
        create a *synthetic* variable ``_stream_<field_name>`` so the
        transformer can inject an assignment and a publish() call.
        """
        best_line = -1
        best_var = None
        best_node = None

        for name in names:
            if name in self.assignments:
                line, node = self.assignments[name]
                end_line = getattr(node, 'end_lineno', line)
                if end_line > best_line:
                    best_line = end_line
                    best_var = name
                    best_node = node

        if best_var is None:
            return None

        # For inline expressions we need a synthetic variable the
        # transformer can reference in the publish() call.
        synthetic_name = f"_stream_{field_name}"
        return FieldComputation(
            field_name=field_name,
            source_variable=synthetic_name,
            computed_at_line=best_line,
            assignment_node=best_node,
            is_synthetic=True,
            value_node=origin_node,
        )


class StreamingTransformer:
    """
    Transform source code to enable partial parameter streaming.
    
    Injects code to:
    1. Import streaming runtime
    2. Create StreamingPublisher after session_id is available
    3. Call publisher.publish() after each field is computed
    4. Invoke next function after first field (with futures for pending)
    """
    
    def __init__(self, analysis: StreamingAnalysis, function_name: str):
        """
        Initialize transformer.
        
        Args:
            analysis: Result from StreamingAnalyzer
            function_name: Name of this function (for logging/debugging)
        """
        self.analysis = analysis
        self.function_name = function_name
    
    def transform(self, source: str) -> Tuple[str, List[str]]:
        """
        Transform source code to enable streaming.
        
        Args:
            source: Original Python source code
            
        Returns:
            Tuple of (transformed_source, list_of_messages)
        """
        messages = []
        lines = source.split('\n')
        
        # Track insertions (line_number -> code_to_insert_after)
        insertions: Dict[int, List[str]] = {}

        # Track return-dict value replacements for synthetic variables.
        # Maps (return_line, field_name) -> synthetic_var_name so we can
        # rewrite the return statement from inline expression to variable.
        return_rewrites: Dict[str, str] = {}  # field_name -> synthetic_var
        
        # 1. Add import at the very beginning (after any existing imports)
        import_line = self._find_import_insertion_point(lines)
        import_code = "from unum_streaming import StreamingPublisher, set_streaming_output"
        
        # 2. Find where to initialize the StreamingPublisher
        #    Should be after session_id is available (usually from event)
        init_line = self._find_init_point(lines)
        
        field_names_str = ", ".join(f'"{f.field_name}"' for f in self.analysis.fields)
        init_code = f'''
    # Streaming: Initialize publisher for incremental parameter streaming
    _streaming_session = event.get('Session', '') or str(id(event))
    _streaming_publisher = StreamingPublisher(
        session_id=_streaming_session,
        source_function="{self.function_name}",
        field_names=[{field_names_str}]
    )'''
        
        # 3. Add publish calls after each field computation
        for i, field in enumerate(self.analysis.fields):
            inject_lines = []

            # For synthetic variables, inject an assignment to capture
            # the inline expression value at the computation point.
            if field.is_synthetic and field.value_node is not None:
                try:
                    expr_src = ast.unparse(field.value_node)
                except AttributeError:
                    # Python < 3.9 fallback — extract from source lines
                    expr_src = self._extract_expression_source(lines, field.value_node)
                inject_lines.append(f"    {field.source_variable} = {expr_src}")
                return_rewrites[field.field_name] = field.source_variable

            publish_code = f"    _streaming_publisher.publish('{field.field_name}', {field.source_variable})"
            inject_lines.append(publish_code)

            # First field also triggers next function invocation
            if i == 0:
                inject_lines.append('''\
    # Streaming: Signal to runtime to invoke next function early with futures
    if _streaming_publisher.should_invoke_next():
        _streaming_payload = _streaming_publisher.get_streaming_payload()
        # Store payload for runtime to pick up and invoke continuation
        set_streaming_output(_streaming_payload)
        _streaming_publisher.mark_next_invoked()''')

            if field.computed_at_line not in insertions:
                insertions[field.computed_at_line] = []
            insertions[field.computed_at_line].extend(inject_lines)
            
            messages.append(f"Stream field '{field.field_name}' after line {field.computed_at_line}")
        
        # Build new source
        new_lines = []
        
        # Add import at the top
        for i, line in enumerate(lines, 1):
            if i == import_line:
                new_lines.append(import_code)
            
            new_lines.append(line)
            
            if i == init_line:
                new_lines.append(init_code)
            
            if i in insertions:
                for code in insertions[i]:
                    new_lines.append(code)

        # 4. Rewrite the return dict to use synthetic variables instead
        #    of inline expressions.
        if return_rewrites:
            result_source = '\n'.join(new_lines)
            result_source = self._rewrite_return_dict(result_source, return_rewrites)
            new_lines = result_source.split('\n')

        return '\n'.join(new_lines), messages

    @staticmethod
    def _extract_expression_source(lines: List[str], node: ast.AST) -> str:
        """Extract expression source text from source lines (Python <3.9 fallback)."""
        if hasattr(node, 'lineno') and hasattr(node, 'end_lineno'):
            start = node.lineno - 1
            end = node.end_lineno
            expr_lines = lines[start:end]
            if expr_lines:
                # Trim to col_offset on first line
                expr_lines[0] = expr_lines[0][node.col_offset:]
                if hasattr(node, 'end_col_offset') and node.end_col_offset:
                    expr_lines[-1] = expr_lines[-1][:node.end_col_offset]
                return ' '.join(l.strip() for l in expr_lines)
        return "None  # Could not extract expression"

    def _rewrite_return_dict(self, source: str, rewrites: Dict[str, str]) -> str:
        """Rewrite the return dict so inline expressions become variable refs.

        Uses line-based replacement to preserve original formatting.
        Finds the return statement in the handler and replaces each field's
        inline expression with the corresponding synthetic variable name.
        """
        lines = source.split('\n')

        # Re-parse to find the return dict with accurate line numbers
        # (line numbers have shifted due to insertions above).
        try:
            tree = ast.parse(source)
        except SyntaxError:
            return source

        ret_node = None
        for node in ast.walk(tree):
            if not isinstance(node, ast.FunctionDef):
                continue
            if node.name != self.analysis.handler_name:
                continue
            for stmt in ast.walk(node):
                if isinstance(stmt, ast.Return) and isinstance(stmt.value, ast.Dict):
                    ret_node = stmt
                    break
            break

        if ret_node is None:
            return source

        ret_dict = ret_node.value

        # For each field that needs rewriting, find its value expression
        # in the source and replace with the synthetic variable name.
        # Process in reverse line order so replacements don't shift offsets.
        replacements = []  # (line_idx, col_start, col_end, new_text)
        for key_node, val_node in zip(ret_dict.keys, ret_dict.values):
            fname = None
            if isinstance(key_node, ast.Constant):
                fname = str(key_node.value)
            elif isinstance(key_node, ast.Str):
                fname = key_node.s

            if fname and fname in rewrites and not isinstance(val_node, ast.Name):
                if hasattr(val_node, 'lineno') and hasattr(val_node, 'end_lineno'):
                    replacements.append((
                        val_node.lineno - 1,   # start line (0-based)
                        val_node.col_offset,
                        val_node.end_lineno - 1,
                        val_node.end_col_offset,
                        rewrites[fname],
                    ))

        # Apply replacements (reverse order to keep positions valid)
        for start_line, col_start, end_line, col_end, var_name in reversed(sorted(replacements)):
            if start_line == end_line:
                # Single-line replacement
                line = lines[start_line]
                lines[start_line] = line[:col_start] + var_name + line[col_end:]
            else:
                # Multi-line replacement: replace first line from col_start,
                # delete middle lines, fix last line up to col_end.
                first = lines[start_line]
                last = lines[end_line]
                lines[start_line] = first[:col_start] + var_name + last[col_end:]
                del lines[start_line + 1:end_line + 1]

        return '\n'.join(lines)
    
    def _find_import_insertion_point(self, lines: List[str]) -> int:
        """Find the line number after which to insert our import"""
        last_import = 0
        for i, line in enumerate(lines, 1):
            stripped = line.strip()
            if stripped.startswith('import ') or stripped.startswith('from '):
                last_import = i
            elif stripped and not stripped.startswith('#') and not stripped.startswith('"""') and not stripped.startswith("'''"):
                if last_import > 0:
                    break
        
        return last_import if last_import > 0 else 1
    
    def _find_init_point(self, lines: List[str]) -> int:
        """
        Find where to initialize the StreamingPublisher.
        
        Should be:
        1. Inside the handler function
        2. After 'event' parameter is available
        3. Before first field computation
        """
        # Find handler function definition
        handler_line = 0
        for i, line in enumerate(lines, 1):
            if f'def {self.analysis.handler_name}' in line:
                handler_line = i
                break
        
        if handler_line == 0:
            return 1
        
        # First field computation line
        first_field_line = min(f.computed_at_line for f in self.analysis.fields)
        
        # Find the end of the docstring (if any) then insert after it
        in_docstring = False
        docstring_char = None
        
        for i in range(handler_line, first_field_line):
            if i > len(lines):
                break
            line = lines[i - 1]
            stripped = line.strip()
            
            # Skip the function definition line itself
            if stripped.startswith('def '):
                continue
            
            # Handle docstrings
            if not in_docstring:
                # Check for docstring start
                if stripped.startswith('"""') or stripped.startswith("'''"):
                    docstring_char = stripped[:3]
                    # Check if single-line docstring (ends on same line)
                    if stripped.count(docstring_char) >= 2:
                        # Single line docstring, continue to next line
                        continue
                    else:
                        # Multi-line docstring starts
                        in_docstring = True
                        continue
                elif stripped.startswith('#'):
                    # Comment line, skip
                    continue
                elif not stripped:
                    # Empty line, skip
                    continue
                else:
                    # Found first actual code line
                    return i - 1  # Insert BEFORE this line (after previous line)
            else:
                # Inside docstring, look for end
                if docstring_char and docstring_char in stripped:
                    # Docstring ends on this line
                    in_docstring = False
                    # Next line will be checked for code
                    continue
        
        # If we didn't find a good spot, use right after handler definition
        return handler_line


def analyze_file(filepath: str) -> StreamingAnalysis:
    """
    Convenience function to analyze a file for streaming.
    
    Args:
        filepath: Path to Python source file
        
    Returns:
        StreamingAnalysis result
    """
    with open(filepath, 'r', encoding='utf-8') as f:
        source = f.read()
    
    analyzer = StreamingAnalyzer()
    return analyzer.analyze(source)


def transform_file(filepath: str, function_name: str) -> Tuple[str, List[str]]:
    """
    Convenience function to transform a file for streaming.
    
    Args:
        filepath: Path to Python source file
        function_name: Name of the function being transformed
        
    Returns:
        Tuple of (transformed_source, messages)
    """
    with open(filepath, 'r', encoding='utf-8') as f:
        source = f.read()
    
    analyzer = StreamingAnalyzer()
    analysis = analyzer.analyze(source)
    
    if not analysis.can_stream:
        return source, [f"Cannot stream: {analysis.reason}"]
    
    transformer = StreamingTransformer(analysis, function_name)
    return transformer.transform(source)


# For testing
if __name__ == "__main__":
    test_source = '''
import json
import time

def compute_field1(data):
    time.sleep(1)
    return {"mean": sum(data) / len(data)}

def compute_field2(data):
    time.sleep(1)
    return {"trend": data[-1] - data[0]}

def compute_field3(data):
    time.sleep(1)
    return {"count": len(data)}

def lambda_handler(event, context):
    data = event.get("data", [1, 2, 3, 4, 5])
    
    # Compute fields
    field1 = compute_field1(data)
    field2 = compute_field2(data)
    field3 = compute_field3(data)
    
    result = {
        "statistical": field1,
        "temporal": field2,
        "metadata": field3
    }
    
    return result
'''
    
    print("=== Analyzing ===")
    analyzer = StreamingAnalyzer()
    analysis = analyzer.analyze(test_source)
    
    print(f"Can stream: {analysis.can_stream}")
    print(f"Reason: {analysis.reason}")
    print(f"Handler: {analysis.handler_name}")
    print(f"Return line: {analysis.return_line}")
    print(f"Fields:")
    for f in analysis.fields:
        print(f"  - {f.field_name}: computed at line {f.computed_at_line} from {f.source_variable}")
    
    if analysis.can_stream:
        print("\n=== Transforming ===")
        transformer = StreamingTransformer(analysis, "TestFunction")
        new_source, messages = transformer.transform(test_source)
        
        print("Messages:")
        for msg in messages:
            print(f"  - {msg}")
        
        print("\n=== Transformed Source ===")
        print(new_source)
